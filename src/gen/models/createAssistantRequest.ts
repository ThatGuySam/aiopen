/* eslint-disable jsdoc/check-alignment */

/**
 * Generated by orval v7.5.0 üç∫
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */
import type { CreateAssistantRequestModel } from './createAssistantRequestModel'
import type { CreateAssistantRequestResponseFormat } from './createAssistantRequestResponseFormat'
import type { CreateAssistantRequestToolResources } from './createAssistantRequestToolResources'
import type { CreateAssistantRequestToolsItem } from './createAssistantRequestToolsItem'
import type { Metadata } from './metadata'
import type { ReasoningEffort } from './reasoningEffort'

export interface CreateAssistantRequest {
  /**
  ID of the model to use. You can use the [List models](/docs/api-reference/models/list) API to see all of your available models, or see our [Model overview](/docs/models) for descriptions of them.
 */
  model: CreateAssistantRequestModel
  /**
   * The name of the assistant. The maximum length is 256 characters.

   * @maxLength 256
   * @nullable
   */
  name?: string | null
  /**
   * The description of the assistant. The maximum length is 512 characters.

   * @maxLength 512
   * @nullable
   */
  description?: string | null
  /**
   * The system instructions that the assistant uses. The maximum length is 256,000 characters.

   * @maxLength 256000
   * @nullable
   */
  instructions?: string | null
  reasoning_effort?: ReasoningEffort
  /**
   * A list of tool enabled on the assistant. There can be a maximum of 128 tools per assistant. Tools can be of types `code_interpreter`, `file_search`, or `function`.

   * @maxItems 128
   */
  tools?: CreateAssistantRequestToolsItem[]
  /**
   * A set of resources that are used by the assistant's tools. The resources are specific to the type of tool. For example, the `code_interpreter` tool requires a list of file IDs, while the `file_search` tool requires a list of vector store IDs.

   * @nullable
   */
  tool_resources?: CreateAssistantRequestToolResources
  metadata?: Metadata
  /**
   * What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.

   * @minimum 0
   * @maximum 2
   * @nullable
   */
  temperature?: number | null
  /**
   * An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.

We generally recommend altering this or temperature but not both.

   * @minimum 0
   * @maximum 1
   * @nullable
   */
  top_p?: number | null
  response_format?: CreateAssistantRequestResponseFormat
}
