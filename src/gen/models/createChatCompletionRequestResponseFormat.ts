/* eslint-disable jsdoc/check-alignment */

import type { ResponseFormatJsonObject } from './responseFormatJsonObject'
import type { ResponseFormatJsonSchema } from './responseFormatJsonSchema'
/**
 * Generated by orval v7.5.0 üç∫
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */
import type { ResponseFormatText } from './responseFormatText'

/**
 * An object specifying the format that the model must output.

Setting to `{ "type": "json_schema", "json_schema": {...} }` enables
Structured Outputs which ensures the model will match your supplied JSON
schema. Learn more in the [Structured Outputs
guide](/docs/guides/structured-outputs).

Setting to `{ "type": "json_object" }` enables JSON mode, which ensures
the message the model generates is valid JSON.

*Important:** when using JSON mode, you **must** also instruct the model
to produce JSON yourself via a system or user message. Without this, the
model may generate an unending stream of whitespace until the generation
reaches the token limit, resulting in a long-running and seemingly "stuck"
request. Also note that the message content may be partially cut off if
`finish_reason="length"`, which indicates the generation exceeded
`max_tokens` or the conversation exceeded the max context length.

 */
export type CreateChatCompletionRequestResponseFormat = ResponseFormatText | ResponseFormatJsonObject | ResponseFormatJsonSchema
