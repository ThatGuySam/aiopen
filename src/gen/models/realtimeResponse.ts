/* eslint-disable jsdoc/check-alignment */

import type { Metadata } from './metadata'
import type { RealtimeConversationItem } from './realtimeConversationItem'
import type { RealtimeResponseMaxOutputTokens } from './realtimeResponseMaxOutputTokens'
import type { RealtimeResponseModalitiesItem } from './realtimeResponseModalitiesItem'
/**
 * Generated by orval v7.5.0 üç∫
 * Do not edit manually.
 * OpenAI API
 * The OpenAI REST API. Please see https://platform.openai.com/docs/api-reference for more details.
 * OpenAPI spec version: 2.3.0
 */
import type { RealtimeResponseObject } from './realtimeResponseObject'
import type { RealtimeResponseOutputAudioFormat } from './realtimeResponseOutputAudioFormat'
import type { RealtimeResponseStatus } from './realtimeResponseStatus'
import type { RealtimeResponseStatusDetails } from './realtimeResponseStatusDetails'
import type { RealtimeResponseUsage } from './realtimeResponseUsage'
import type { RealtimeResponseVoice } from './realtimeResponseVoice'

/**
 * The response resource.
 */
export interface RealtimeResponse {
  /** The unique ID of the response. */
  id?: string
  /** The object type, must be `realtime.response`. */
  object?: RealtimeResponseObject
  /**
 The final status of the response (`completed`, `cancelled`, `failed`, or
`incomplete`).
 */
  status?: RealtimeResponseStatus
  /** Additional details about the status. */
  status_details?: RealtimeResponseStatusDetails
  /** The list of output items generated by the response. */
  output?: RealtimeConversationItem[]
  metadata?: Metadata
  /**
 Usage statistics for the Response, this will correspond to billing. A
Realtime API session will maintain a conversation context and append new
Items to the Conversation, thus output from previous turns (text and
audio tokens) will become the input for later turns.
 */
  usage?: RealtimeResponseUsage
  /**
 Which conversation the response is added to, determined by the `conversation`
field in the `response.create` event. If `auto`, the response will be added to
the default conversation and the value of `conversation_id` will be an id like
`conv_1234`. If `none`, the response will not be added to any conversation and
the value of `conversation_id` will be `null`. If responses are being triggered
by server VAD, the response will be added to the default conversation, thus
the `conversation_id` will be an id like `conv_1234`.
 */
  conversation_id?: string
  /**
 The voice the model used to respond.
Current voice options are `alloy`, `ash`, `ballad`, `coral`, `echo` `sage`,
`shimmer` and `verse`.
 */
  voice?: RealtimeResponseVoice
  /**
 The set of modalities the model used to respond. If there are multiple modalities,
the model will pick one, for example if `modalities` is `["text", "audio"]`, the model
could be responding in either text or audio.
 */
  modalities?: RealtimeResponseModalitiesItem[]
  /**
  The format of output audio. Options are `pcm16`, `g711_ulaw`, or `g711_alaw`.
 */
  output_audio_format?: RealtimeResponseOutputAudioFormat
  /**
  Sampling temperature for the model, limited to [0.6, 1.2]. Defaults to 0.8.
 */
  temperature?: number
  /**
 Maximum number of output tokens for a single assistant response,
inclusive of tool calls, that was used in this response.
 */
  max_output_tokens?: RealtimeResponseMaxOutputTokens
}
